{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download the WordNet data\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "word = \"determine\"\n",
    "synonyms = get_synonyms(word)\n",
    "sophisticated_word = max(synonyms, key=len)  # Choose the longest synonym as a 'sophisticated' word\n",
    "\n",
    "print(f\"Sophisticated word for {word}: {sophisticated_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135055bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install spacy \n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c193f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae2d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 1.0\n",
    "#Very basic version\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to get sophisticated synonym\n",
    "def get_sophisticated_synonym(word, pos):\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    if synsets:\n",
    "        for synset in synsets:\n",
    "            sophisticated_word = synset.lemmas()[0].name().replace('_', ' ')\n",
    "            if sophisticated_word.lower() != word.lower():\n",
    "                return sophisticated_word\n",
    "    return word\n",
    "\n",
    "# POS mapping from NLTK to WordNet\n",
    "pos_map = {\n",
    "    'NN': wn.NOUN,\n",
    "    'VB': wn.VERB,\n",
    "    'JJ': wn.ADJ,\n",
    "    'RB': wn.ADV\n",
    "}\n",
    "\n",
    "# Function to enhance sentence\n",
    "def enhance_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    enhanced_sentence = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        wn_tag = pos_map.get(tag[:2])\n",
    "        if wn_tag:\n",
    "            enhanced_word = get_sophisticated_synonym(word, wn_tag)\n",
    "            enhanced_sentence.append(enhanced_word)\n",
    "        else:\n",
    "            enhanced_sentence.append(word)\n",
    "    return ' '.join(enhanced_sentence)\n",
    "\n",
    "# Example sentences\n",
    "simple_sentences = input(\"Enter the Sentence: \")\n",
    "\n",
    "print(f\"Enhanced: {enhance_sentence(simple_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de87a6",
   "metadata": {},
   "source": [
    "## Version 2.0 :- Sentimental Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4100831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sophisticated synonym\n",
    "def get_sophisticated_synonym(word, pos):\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    if synsets:\n",
    "        for synset in synsets:\n",
    "            # Choose the first lemma as a sophisticated word (can be improved)\n",
    "            sophisticated_word = synset.lemmas()[0].name().replace('_', ' ')\n",
    "            if sophisticated_word.lower() != word.lower():\n",
    "                return sophisticated_word\n",
    "    return word\n",
    "\n",
    "# POS mapping from NLTK to WordNet\n",
    "pos_map = {\n",
    "    'NN': wn.NOUN,\n",
    "    'VB': wn.VERB,\n",
    "    'JJ': wn.ADJ,\n",
    "    'RB': wn.ADV\n",
    "}\n",
    "\n",
    "# Function to enhance sentence with positive tone\n",
    "def enhance_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    enhanced_sentence = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        wn_tag = pos_map.get(tag[:2])\n",
    "        if wn_tag:\n",
    "            enhanced_word = get_sophisticated_synonym(word, wn_tag)\n",
    "            enhanced_sentence.append(enhanced_word)\n",
    "        else:\n",
    "            enhanced_sentence.append(word)\n",
    "    return ' '.join(enhanced_sentence)\n",
    "\n",
    "# Function to adjust the tone of the sentence to be more positive and kind-hearted\n",
    "def make_kind_hearted(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    enhanced_sentence = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        wn_tag = pos_map.get(tag[:2])\n",
    "        if wn_tag:\n",
    "            enhanced_word = get_sophisticated_synonym(word, wn_tag)\n",
    "            if sia.polarity_scores(enhanced_word)['compound'] >= 0:\n",
    "                enhanced_sentence.append(enhanced_word)\n",
    "            else:\n",
    "                enhanced_sentence.append(word)\n",
    "        else:\n",
    "            enhanced_sentence.append(word)\n",
    "    return ' '.join(enhanced_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "simple_sentences = input(\"Enter the Sentence: \")\n",
    "\n",
    "enhanced = enhance_sentence(simple_sentences)\n",
    "\n",
    "kind_hearted = make_kind_hearted(simple_sentences)\n",
    "\n",
    "print(f\"Enhanced: {enhanced}\")\n",
    "print(f\"Kind-hearted: {kind_hearted}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23761794",
   "metadata": {},
   "source": [
    "## Version 3.0 :- Making Gramatically correct sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk transformers language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import language_tool_python\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize Sentiment Intensity Analyzer and LanguageTool\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "tool = language_tool_python.LanguageTool('en-US')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2548798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sophisticated synonym\n",
    "def get_sophisticated_synonym(word, pos):\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    if synsets:\n",
    "        for synset in synsets:\n",
    "            sophisticated_word = synset.lemmas()[0].name().replace('_', ' ')\n",
    "            if sophisticated_word.lower() != word.lower():\n",
    "                return sophisticated_word\n",
    "    return word\n",
    "\n",
    "# POS mapping from NLTK to WordNet\n",
    "pos_map = {\n",
    "    'NN': wn.NOUN,\n",
    "    'VB': wn.VERB,\n",
    "    'JJ': wn.ADJ,\n",
    "    'RB': wn.ADV\n",
    "}\n",
    "\n",
    "# Function to enhance sentence with positive tone\n",
    "def enhance_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    enhanced_sentence = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        wn_tag = pos_map.get(tag[:2])\n",
    "        if wn_tag:\n",
    "            enhanced_word = get_sophisticated_synonym(word, wn_tag)\n",
    "            enhanced_sentence.append(enhanced_word)\n",
    "        else:\n",
    "            enhanced_sentence.append(word)\n",
    "    return ' '.join(enhanced_sentence)\n",
    "\n",
    "# Function to adjust the tone of the sentence to be more positive and kind-hearted\n",
    "def make_kind_hearted(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    enhanced_sentence = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        wn_tag = pos_map.get(tag[:2])\n",
    "        if wn_tag:\n",
    "            enhanced_word = get_sophisticated_synonym(word, wn_tag)\n",
    "            if sia.polarity_scores(enhanced_word)['compound'] >= 0:\n",
    "                enhanced_sentence.append(enhanced_word)\n",
    "            else:\n",
    "                enhanced_sentence.append(word)\n",
    "        else:\n",
    "            enhanced_sentence.append(word)\n",
    "    return ' '.join(enhanced_sentence)\n",
    "\n",
    "# Function to check and correct grammar\n",
    "def correct_grammar(sentence):\n",
    "    matches = tool.check(sentence)\n",
    "    corrected_sentence = language_tool_python.utils.correct(sentence, matches)\n",
    "    return corrected_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d9db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "simple_sentences = input(\"Enter the Sentence: \")\n",
    "\n",
    "enhanced = enhance_sentence(simple_sentences)\n",
    "kind_hearted = make_kind_hearted(enhanced)\n",
    "grammatically_correct = correct_grammar(kind_hearted)\n",
    "\n",
    "print(f\"Enhanced: {enhanced}\")\n",
    "print(f\"Kind-hearted: {kind_hearted}\")\n",
    "print(f\"Grammatically Correct: {grammatically_correct}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
